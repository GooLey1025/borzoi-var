{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 0.2510758936405182\n",
      "Test_acc: 0.3\n",
      "--------------------------\n",
      "Epoch 1, loss: 0.20274785161018372\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 2, loss: 0.19009871780872345\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 3, loss: 0.1788853108882904\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 4, loss: 0.16892117261886597\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 5, loss: 0.1604090929031372\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 6, loss: 0.1532016396522522\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 7, loss: 0.1470983773469925\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 8, loss: 0.14190389215946198\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 9, loss: 0.13744837045669556\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 10, loss: 0.13359171152114868\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 11, loss: 0.1302211731672287\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 12, loss: 0.1272471398115158\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 13, loss: 0.12459848076105118\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 14, loss: 0.12221872061491013\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 15, loss: 0.12006287276744843\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 16, loss: 0.11809486895799637\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 17, loss: 0.11628559976816177\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 18, loss: 0.11461146175861359\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 19, loss: 0.11305315047502518\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 20, loss: 0.11159481108188629\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 21, loss: 0.11022330075502396\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 22, loss: 0.10892768204212189\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 23, loss: 0.10769879817962646\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 24, loss: 0.10652889311313629\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 25, loss: 0.10541145503520966\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 26, loss: 0.10434088855981827\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 27, loss: 0.1033124327659607\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 28, loss: 0.10232198238372803\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 29, loss: 0.10136601328849792\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 30, loss: 0.10044143348932266\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 31, loss: 0.09954557567834854\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 32, loss: 0.09867610037326813\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 33, loss: 0.09783095866441727\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 34, loss: 0.09700833261013031\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 35, loss: 0.09620664268732071\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 36, loss: 0.09542445838451385\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 37, loss: 0.09466053545475006\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 38, loss: 0.0939137414097786\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 39, loss: 0.09318307042121887\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 40, loss: 0.09246762096881866\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 41, loss: 0.09176657348871231\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 42, loss: 0.09107920527458191\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 43, loss: 0.09040486812591553\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 44, loss: 0.08974291384220123\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 45, loss: 0.08909283578395844\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 46, loss: 0.08845411986112595\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 47, loss: 0.08782629668712616\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 48, loss: 0.08720897138118744\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 49, loss: 0.08660174161195755\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 50, loss: 0.08600424975156784\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 51, loss: 0.08541616052389145\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 52, loss: 0.0848371833562851\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 53, loss: 0.0842670351266861\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 54, loss: 0.08370544016361237\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 55, loss: 0.0831521600484848\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 56, loss: 0.0826069638133049\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 57, loss: 0.08206962049007416\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 58, loss: 0.08153995126485825\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 59, loss: 0.08101775497198105\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 60, loss: 0.08050284534692764\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 61, loss: 0.0799950435757637\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 62, loss: 0.07949420809745789\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 63, loss: 0.07900016009807587\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 64, loss: 0.0785127729177475\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 65, loss: 0.07803190499544144\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 66, loss: 0.07755741477012634\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 67, loss: 0.07708916813135147\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 68, loss: 0.07662704586982727\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 69, loss: 0.07617095112800598\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 70, loss: 0.07572074234485626\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 71, loss: 0.07527630776166916\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 72, loss: 0.0748375654220581\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 73, loss: 0.07440438866615295\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 74, loss: 0.07397670298814774\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 75, loss: 0.0735543891787529\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 76, loss: 0.07313735783100128\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 77, loss: 0.07272553443908691\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 78, loss: 0.07231880724430084\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 79, loss: 0.07191711664199829\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 80, loss: 0.0715203657746315\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 81, loss: 0.0711284726858139\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 82, loss: 0.07074135541915894\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 83, loss: 0.07035894691944122\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 84, loss: 0.0699811577796936\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 85, loss: 0.0696079283952713\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 86, loss: 0.06923917680978775\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 87, loss: 0.06887483596801758\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 88, loss: 0.06851483881473541\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 89, loss: 0.06815911829471588\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 90, loss: 0.06780759245157242\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 91, loss: 0.06746022403240204\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 92, loss: 0.06711693108081818\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 93, loss: 0.06677764654159546\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 94, loss: 0.06644231826066971\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 95, loss: 0.06611088663339615\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 96, loss: 0.06578329205513\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 97, loss: 0.0654594749212265\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 98, loss: 0.06513937562704086\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 99, loss: 0.06482294201850891\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 100, loss: 0.06451012194156647\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 101, loss: 0.06420086324214935\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 102, loss: 0.0638950988650322\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 103, loss: 0.06359279155731201\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 104, loss: 0.06329387426376343\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 105, loss: 0.06299830228090286\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 106, loss: 0.06270604580640793\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 107, loss: 0.062417030334472656\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 108, loss: 0.06213122606277466\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 109, loss: 0.061848580837249756\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 110, loss: 0.06156904250383377\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 111, loss: 0.06129256263375282\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 112, loss: 0.06101911514997482\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 113, loss: 0.0607486367225647\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 114, loss: 0.06048108637332916\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 115, loss: 0.06021644175052643\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 116, loss: 0.059954628348350525\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 117, loss: 0.059695638716220856\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 118, loss: 0.05943940579891205\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 119, loss: 0.059185899794101715\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 120, loss: 0.05893509089946747\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 121, loss: 0.05868692696094513\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 122, loss: 0.05844137445092201\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 123, loss: 0.05819840356707573\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 124, loss: 0.0579579696059227\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 125, loss: 0.057720035314559937\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 126, loss: 0.057484567165374756\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 127, loss: 0.05725153535604477\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 128, loss: 0.057020895183086395\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 129, loss: 0.05679262429475784\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 130, loss: 0.056566692888736725\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 131, loss: 0.05634304881095886\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 132, loss: 0.056121669709682465\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 133, loss: 0.055902525782585144\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 134, loss: 0.05568558722734451\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 135, loss: 0.055470824241638184\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 136, loss: 0.05525820702314377\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 137, loss: 0.05504769831895828\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 138, loss: 0.054839275777339935\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 139, loss: 0.05463290959596634\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 140, loss: 0.054428569972515106\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 141, loss: 0.05422622710466385\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 142, loss: 0.054025858640670776\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 143, loss: 0.0538274347782135\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 144, loss: 0.05363093689084053\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 145, loss: 0.053436316549777985\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 146, loss: 0.05324358120560646\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 147, loss: 0.05305267870426178\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 148, loss: 0.05286359786987305\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 149, loss: 0.05267631262540817\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 150, loss: 0.05249079316854477\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 151, loss: 0.052307017147541046\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 152, loss: 0.05212496966123581\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 153, loss: 0.05194462090730667\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 154, loss: 0.051765941083431244\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 155, loss: 0.05158892646431923\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 156, loss: 0.05141354724764824\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 157, loss: 0.05123976990580559\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 158, loss: 0.05106757953763008\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 159, loss: 0.05089697241783142\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 160, loss: 0.05072791129350662\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 161, loss: 0.050560370087623596\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 162, loss: 0.050394341349601746\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 163, loss: 0.050229813903570175\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 164, loss: 0.0500667504966259\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 165, loss: 0.04990514740347862\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 166, loss: 0.049744971096515656\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 167, loss: 0.04958619922399521\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 168, loss: 0.04942884296178818\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 169, loss: 0.04927285015583038\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 170, loss: 0.04911823198199272\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 171, loss: 0.048964954912662506\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 172, loss: 0.04881300777196884\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 173, loss: 0.04866236448287964\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 174, loss: 0.0485130213201046\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 175, loss: 0.04836495965719223\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 176, loss: 0.048218149691820145\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 177, loss: 0.04807259514927864\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 178, loss: 0.04792828485369682\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 179, loss: 0.04778517037630081\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 180, loss: 0.0476432666182518\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 181, loss: 0.047502551227808\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 182, loss: 0.047363005578517914\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 183, loss: 0.04722461849451065\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 184, loss: 0.04708738625049591\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 185, loss: 0.04695127159357071\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 186, loss: 0.046816274523735046\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 187, loss: 0.04668238013982773\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 188, loss: 0.046549584716558456\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 189, loss: 0.04641786217689514\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 190, loss: 0.04628720507025719\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 191, loss: 0.0461575947701931\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 192, loss: 0.046029023826122284\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 193, loss: 0.04590148478746414\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 194, loss: 0.04577496275305748\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 195, loss: 0.045649439096450806\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 196, loss: 0.045524902641773224\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 197, loss: 0.045401349663734436\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 198, loss: 0.045278772711753845\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 199, loss: 0.045157141983509064\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 200, loss: 0.04503646492958069\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 201, loss: 0.04491671174764633\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 202, loss: 0.04479789733886719\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 203, loss: 0.04467998817563057\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 204, loss: 0.04456298053264618\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 205, loss: 0.04444686323404312\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 206, loss: 0.044331640005111694\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 207, loss: 0.04421728104352951\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 208, loss: 0.04410379007458687\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 209, loss: 0.043991148471832275\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 210, loss: 0.04387935623526573\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 211, loss: 0.04376840218901634\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 212, loss: 0.043658263981342316\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 213, loss: 0.04354894533753395\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 214, loss: 0.04344043508172035\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 215, loss: 0.043332718312740326\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 216, loss: 0.04322579503059387\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 217, loss: 0.0431196503341198\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 218, loss: 0.0430142767727375\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 219, loss: 0.04290967062115669\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 220, loss: 0.04280581325292587\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 221, loss: 0.04270271211862564\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 222, loss: 0.04260034114122391\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 223, loss: 0.04249870404601097\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 224, loss: 0.042397793382406235\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 225, loss: 0.0422975979745388\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 226, loss: 0.04219810664653778\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 227, loss: 0.042099323123693466\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 228, loss: 0.04200122877955437\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 229, loss: 0.041903816163539886\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 230, loss: 0.041807085275650024\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 231, loss: 0.04171103239059448\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 232, loss: 0.04161563515663147\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 233, loss: 0.041520893573760986\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 234, loss: 0.04142681136727333\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 235, loss: 0.041333358734846115\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 236, loss: 0.04124055802822113\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 237, loss: 0.04114837944507599\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 238, loss: 0.04105683043599129\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 239, loss: 0.04096589609980583\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 240, loss: 0.040875568985939026\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 241, loss: 0.04078585281968117\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 242, loss: 0.04069673642516136\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 243, loss: 0.04060821235179901\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 244, loss: 0.040520280599594116\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 245, loss: 0.040432918816804886\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 246, loss: 0.040346138179302216\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 247, loss: 0.04025992751121521\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 248, loss: 0.04017426818609238\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 249, loss: 0.040089186280965805\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 250, loss: 0.04000464826822281\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 251, loss: 0.039920657873153687\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 252, loss: 0.03983721137046814\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 253, loss: 0.039754293859004974\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 254, loss: 0.03967191278934479\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 255, loss: 0.03959006071090698\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 256, loss: 0.03950872644782066\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 257, loss: 0.03942791372537613\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 258, loss: 0.03934760391712189\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 259, loss: 0.03926780819892883\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 260, loss: 0.039188507944345474\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 261, loss: 0.03910969942808151\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 262, loss: 0.03903138265013695\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 263, loss: 0.03895355761051178\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 264, loss: 0.03887622058391571\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 265, loss: 0.038799360394477844\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 266, loss: 0.03872296214103699\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 267, loss: 0.038647040724754333\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 268, loss: 0.038571588695049286\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 269, loss: 0.03849659115076065\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 270, loss: 0.03842204809188843\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 271, loss: 0.03834795951843262\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 272, loss: 0.038274310529232025\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 273, loss: 0.03820110857486725\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 274, loss: 0.03812834620475769\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 275, loss: 0.03805601969361305\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 276, loss: 0.037984125316143036\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 277, loss: 0.037912655621767044\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 278, loss: 0.03784160315990448\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 279, loss: 0.03777097910642624\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 280, loss: 0.037700772285461426\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 281, loss: 0.03763097524642944\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 282, loss: 0.037561580538749695\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 283, loss: 0.03749259561300278\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 284, loss: 0.0374239981174469\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 285, loss: 0.03735581785440445\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 286, loss: 0.03728801757097244\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 287, loss: 0.03722061216831207\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 288, loss: 0.037153590470552444\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 289, loss: 0.03708695247769356\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 290, loss: 0.03702070564031601\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 291, loss: 0.036954816430807114\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 292, loss: 0.03688931092619896\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 293, loss: 0.03682417795062065\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 294, loss: 0.03675941005349159\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 295, loss: 0.036694999784231186\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 296, loss: 0.03663095459342003\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 297, loss: 0.036567263305187225\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 298, loss: 0.036503925919532776\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 299, loss: 0.03644094616174698\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 300, loss: 0.03637830540537834\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 301, loss: 0.03631601482629776\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 302, loss: 0.03625406324863434\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 303, loss: 0.036192454397678375\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 304, loss: 0.03613118827342987\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 305, loss: 0.03607024624943733\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 306, loss: 0.03600963577628136\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 307, loss: 0.035949356853961945\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 308, loss: 0.0358894020318985\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 309, loss: 0.03582976758480072\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 310, loss: 0.03577045351266861\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 311, loss: 0.03571145981550217\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 312, loss: 0.035652779042720795\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 313, loss: 0.035594407469034195\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 314, loss: 0.035536352545022964\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 315, loss: 0.03547859191894531\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 316, loss: 0.03542114421725273\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 317, loss: 0.035363998264074326\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 318, loss: 0.0353071466088295\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 319, loss: 0.035250596702098846\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 320, loss: 0.03519434481859207\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 321, loss: 0.03513837605714798\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 322, loss: 0.03508269786834717\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 323, loss: 0.03502730652689934\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 324, loss: 0.034972209483385086\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 325, loss: 0.034917380660772324\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 326, loss: 0.03486285358667374\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 327, loss: 0.03480858355760574\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 328, loss: 0.03475459665060043\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 329, loss: 0.034700892865657806\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 330, loss: 0.03464745730161667\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 331, loss: 0.03459428250789642\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 332, loss: 0.034541383385658264\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 333, loss: 0.0344887413084507\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 334, loss: 0.03443637117743492\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 335, loss: 0.034384261816740036\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 336, loss: 0.034332405775785446\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 337, loss: 0.03428081423044205\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 338, loss: 0.03422946482896805\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 339, loss: 0.03417838364839554\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 340, loss: 0.03412754833698273\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 341, loss: 0.034076955169439316\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 342, loss: 0.0340266153216362\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 343, loss: 0.03397652506828308\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 344, loss: 0.03392667695879936\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 345, loss: 0.03387707099318504\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 346, loss: 0.033827703446149826\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 347, loss: 0.03377857059240341\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 348, loss: 0.0337296761572361\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 349, loss: 0.03368101641535759\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 350, loss: 0.03363259509205818\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 351, loss: 0.03358439728617668\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 352, loss: 0.033536430448293686\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 353, loss: 0.03348869830369949\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 354, loss: 0.03344118595123291\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 355, loss: 0.033393897116184235\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 356, loss: 0.03334682807326317\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 357, loss: 0.03329998627305031\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 358, loss: 0.033253371715545654\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 359, loss: 0.03320695459842682\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 360, loss: 0.03316076472401619\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 361, loss: 0.03311479091644287\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 362, loss: 0.03306903690099716\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 363, loss: 0.03302347660064697\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 364, loss: 0.03297813981771469\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 365, loss: 0.03293300420045853\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 366, loss: 0.032888080924749374\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 367, loss: 0.03284336254000664\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 368, loss: 0.032798849046230316\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 369, loss: 0.032754525542259216\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 370, loss: 0.03271041437983513\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 371, loss: 0.03266649693250656\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 372, loss: 0.03262278810143471\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 373, loss: 0.03257926553487778\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 374, loss: 0.032535940408706665\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 375, loss: 0.03249281272292137\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 376, loss: 0.032449871301651\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 377, loss: 0.03240712732076645\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 378, loss: 0.03236456960439682\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 379, loss: 0.03232220560312271\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 380, loss: 0.03228002414107323\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 381, loss: 0.032238028943538666\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 382, loss: 0.032196227461099625\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 383, loss: 0.03215460479259491\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 384, loss: 0.03211315721273422\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 385, loss: 0.03207189962267876\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 386, loss: 0.03203080967068672\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 387, loss: 0.031989917159080505\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 388, loss: 0.03194918856024742\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 389, loss: 0.031908631324768066\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 390, loss: 0.03186826407909393\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 391, loss: 0.03182806447148323\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 392, loss: 0.03178802877664566\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 393, loss: 0.03174816817045212\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 394, loss: 0.0317084863781929\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 395, loss: 0.03166896477341652\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 396, loss: 0.03162960708141327\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 397, loss: 0.03159042447805405\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 398, loss: 0.031551409512758255\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 399, loss: 0.031512551009655\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 400, loss: 0.03147386386990547\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 401, loss: 0.03143533319234848\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 402, loss: 0.03139696270227432\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 403, loss: 0.031358759850263596\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 404, loss: 0.031320713460445404\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 405, loss: 0.03128281980752945\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 406, loss: 0.031245088204741478\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 407, loss: 0.031207511201500893\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 408, loss: 0.031170088797807693\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 409, loss: 0.03113282099366188\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 410, loss: 0.031095709651708603\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 411, loss: 0.031058747321367264\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 412, loss: 0.031021934002637863\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 413, loss: 0.030985280871391296\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 414, loss: 0.030948758125305176\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 415, loss: 0.03091239556670189\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 416, loss: 0.03087618201971054\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 417, loss: 0.030840106308460236\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 418, loss: 0.030804181471467018\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 419, loss: 0.030768394470214844\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 420, loss: 0.030732765793800354\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 421, loss: 0.03069726936519146\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 422, loss: 0.03066191077232361\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 423, loss: 0.030626695603132248\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 424, loss: 0.030591625720262527\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 425, loss: 0.030556701123714447\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 426, loss: 0.030521895736455917\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 427, loss: 0.030487239360809326\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 428, loss: 0.03045271337032318\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 429, loss: 0.030418332666158676\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 430, loss: 0.03038407489657402\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 431, loss: 0.030349958688020706\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 432, loss: 0.030315976589918137\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 433, loss: 0.03028212860226631\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 434, loss: 0.030248399823904037\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 435, loss: 0.030214808881282806\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 436, loss: 0.03018135204911232\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 437, loss: 0.030148018151521683\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 438, loss: 0.030114810913801193\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 439, loss: 0.03008173406124115\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 440, loss: 0.030048782005906105\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 441, loss: 0.030015960335731506\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 442, loss: 0.029983259737491608\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 443, loss: 0.029950687661767006\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 444, loss: 0.029918234795331955\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 445, loss: 0.02988590858876705\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 446, loss: 0.02985370345413685\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 447, loss: 0.029821623116731644\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 448, loss: 0.029789648950099945\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 449, loss: 0.02975781448185444\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 450, loss: 0.02972608432173729\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 451, loss: 0.02969447337090969\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 452, loss: 0.02966298907995224\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 453, loss: 0.029631618410348892\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 454, loss: 0.029600363224744797\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 455, loss: 0.029569216072559357\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 456, loss: 0.029538197442889214\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 457, loss: 0.029507286846637726\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 458, loss: 0.029476486146450043\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 459, loss: 0.02944580465555191\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 460, loss: 0.02941523678600788\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 461, loss: 0.029384780675172806\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 462, loss: 0.029354430735111237\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 463, loss: 0.029324190691113472\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 464, loss: 0.02929406240582466\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 465, loss: 0.029264045879244804\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 466, loss: 0.029234133660793304\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 467, loss: 0.029204338788986206\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 468, loss: 0.02917463332414627\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 469, loss: 0.029145054519176483\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 470, loss: 0.02911556325852871\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 471, loss: 0.029086191207170486\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 472, loss: 0.02905692532658577\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 473, loss: 0.029027748852968216\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 474, loss: 0.028998689725995064\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 475, loss: 0.028969723731279373\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 476, loss: 0.028940871357917786\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 477, loss: 0.02891211397945881\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 478, loss: 0.02888345718383789\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 479, loss: 0.02885489910840988\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 480, loss: 0.02882644161581993\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 481, loss: 0.028798099607229233\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 482, loss: 0.0287698432803154\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 483, loss: 0.02874167636036873\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 484, loss: 0.028713619336485863\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 485, loss: 0.028685666620731354\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 486, loss: 0.02865780144929886\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 487, loss: 0.028630033135414124\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 488, loss: 0.0286023560911417\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 489, loss: 0.028574779629707336\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 490, loss: 0.028547298163175583\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 491, loss: 0.02851990982890129\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 492, loss: 0.028492620214819908\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 493, loss: 0.02846541628241539\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 494, loss: 0.02843831107020378\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 495, loss: 0.028411291539669037\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 496, loss: 0.028384368866682053\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 497, loss: 0.028357531875371933\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 498, loss: 0.028330795466899872\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 499, loss: 0.028304148465394974\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 数据准备\n",
    "x_data = datasets.load_iris().data\n",
    "y_data = datasets.load_iris().target\n",
    "\n",
    "# 确保数据类型为 float32\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.int32)\n",
    "\n",
    "np.random.seed(1160)\n",
    "np.random.shuffle(x_data)\n",
    "np.random.seed(1160)\n",
    "np.random.shuffle(y_data)\n",
    "\n",
    "x_train = x_data[:-30]\n",
    "y_train = y_data[:-30]\n",
    "x_test = x_data[-30:]\n",
    "y_test = y_data[-30:]\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "# 模型参数 - 确保使用 float32\n",
    "w1 = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1, dtype=tf.float32))\n",
    "b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1, dtype=tf.float32))\n",
    "\n",
    "# 训练参数\n",
    "lr = 0.1\n",
    "train_loss_results = []\n",
    "test_acc = []\n",
    "epoch = 500\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(epoch):\n",
    "    loss_all = 0\n",
    "    for step, (x_train, y_train) in enumerate(train_db):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 确保输入数据类型为 float32\n",
    "            x_train = tf.cast(x_train, tf.float32)\n",
    "            y = tf.matmul(x_train, w1) + b1\n",
    "            y = tf.nn.softmax(y)\n",
    "            y_ = tf.one_hot(y_train, depth=3)\n",
    "            loss = tf.reduce_mean(tf.square(y_ - y))\n",
    "            loss_all += loss\n",
    "\n",
    "        grads = tape.gradient(loss, [w1, b1])\n",
    "        w1.assign_sub(lr * grads[0])\n",
    "        b1.assign_sub(lr * grads[1])\n",
    "    \n",
    "    avg_loss = loss_all / len(train_db)\n",
    "    train_loss_results.append(avg_loss)\n",
    "    print(\"Epoch {}, loss: {}\".format(epoch, avg_loss))\n",
    "    \n",
    "    # 测试\n",
    "    total_correct, total_number = 0, 0\n",
    "    for x_test, y_test in test_db:\n",
    "        # 确保测试数据也是 float32\n",
    "        x_test = tf.cast(x_test, tf.float32)\n",
    "        y = tf.matmul(x_test, w1) + b1\n",
    "        y = tf.nn.softmax(y)\n",
    "        pred = tf.argmax(y, axis=1)\n",
    "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
    "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
    "        correct = tf.reduce_sum(correct)\n",
    "        total_correct += int(correct)\n",
    "        total_number += x_test.shape[0]\n",
    "    acc = total_correct / total_number\n",
    "    test_acc.append(acc)\n",
    "    print(\"Test_acc: {}\".format(acc))\n",
    "    print(\"--------------------------\")\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Loss Function Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(train_loss_results, label=\"$Loss$\")\n",
    "plt.legend()\n",
    "\n",
    "# 绘制准确率曲线\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Acc Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Acc')\n",
    "plt.plot(test_acc, label=\"$Accuracy$\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 2.0627 - sparse_categorical_accuracy: 0.3833\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 842us/step - loss: 1.4013 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 727us/step - loss: 1.1723 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 728us/step - loss: 1.1963 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 709us/step - loss: 1.4124 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 780us/step - loss: 1.1425 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 754us/step - loss: 1.1235 - sparse_categorical_accuracy: 0.4083\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 738us/step - loss: 1.4419 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 701us/step - loss: 1.3457 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 707us/step - loss: 1.8645 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 762us/step - loss: 1.3389 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 771us/step - loss: 1.9190 - sparse_categorical_accuracy: 0.2417\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 722us/step - loss: 1.8654 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 727us/step - loss: 1.2543 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 692us/step - loss: 1.4294 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 691us/step - loss: 1.3142 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 694us/step - loss: 1.6213 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 681us/step - loss: 1.3962 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 663us/step - loss: 1.4318 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.2238 - sparse_categorical_accuracy: 0.3500 - val_loss: 1.1711 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 825us/step - loss: 1.3680 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 718us/step - loss: 1.5352 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 763us/step - loss: 1.4190 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 887us/step - loss: 1.2913 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 885us/step - loss: 1.2207 - sparse_categorical_accuracy: 0.3833\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 809us/step - loss: 1.1860 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 798us/step - loss: 1.4748 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 776us/step - loss: 1.1899 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 780us/step - loss: 1.3705 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 770us/step - loss: 1.3372 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 760us/step - loss: 1.1702 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 759us/step - loss: 1.2470 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 694us/step - loss: 1.3384 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 712us/step - loss: 1.5474 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 765us/step - loss: 1.4213 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 738us/step - loss: 1.3637 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 745us/step - loss: 1.2292 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 788us/step - loss: 1.4585 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 821us/step - loss: 1.2583 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.3213 - sparse_categorical_accuracy: 0.3500 - val_loss: 1.5348 - val_sparse_categorical_accuracy: 0.3667\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 843us/step - loss: 1.4861 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 773us/step - loss: 1.8076 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 1.4972 - sparse_categorical_accuracy: 0.3833\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 792us/step - loss: 1.2171 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 731us/step - loss: 1.3786 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 764us/step - loss: 1.3411 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 821us/step - loss: 1.3852 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 756us/step - loss: 2.0492 - sparse_categorical_accuracy: 0.2583\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 818us/step - loss: 1.3383 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 766us/step - loss: 1.4404 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 878us/step - loss: 1.3094 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 877us/step - loss: 1.4085 - sparse_categorical_accuracy: 0.2583\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 829us/step - loss: 1.5290 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 897us/step - loss: 1.2550 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 834us/step - loss: 1.2757 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 817us/step - loss: 1.6310 - sparse_categorical_accuracy: 0.2583\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 759us/step - loss: 2.1058 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 804us/step - loss: 1.4371 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 769us/step - loss: 1.3506 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.3475 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.0995 - val_sparse_categorical_accuracy: 0.4667\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 837us/step - loss: 1.2809 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 848us/step - loss: 1.4245 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 817us/step - loss: 1.4268 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 793us/step - loss: 1.2524 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 817us/step - loss: 1.3596 - sparse_categorical_accuracy: 0.3833\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 790us/step - loss: 1.7261 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 892us/step - loss: 1.4164 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 788us/step - loss: 1.2165 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 733us/step - loss: 1.3761 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 841us/step - loss: 1.2669 - sparse_categorical_accuracy: 0.2667\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 845us/step - loss: 1.2202 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 819us/step - loss: 1.3498 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 780us/step - loss: 1.2573 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 749us/step - loss: 1.4558 - sparse_categorical_accuracy: 0.2417\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 761us/step - loss: 1.3474 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 770us/step - loss: 1.2351 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 746us/step - loss: 1.2632 - sparse_categorical_accuracy: 0.3833\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 732us/step - loss: 1.0891 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 758us/step - loss: 1.2484 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.4722 - sparse_categorical_accuracy: 0.2917 - val_loss: 1.3599 - val_sparse_categorical_accuracy: 0.2333\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 794us/step - loss: 1.1110 - sparse_categorical_accuracy: 0.4333\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 757us/step - loss: 1.2687 - sparse_categorical_accuracy: 0.4167\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 841us/step - loss: 1.2849 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 848us/step - loss: 1.6479 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 855us/step - loss: 1.4118 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 846us/step - loss: 1.3438 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 734us/step - loss: 1.4989 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 903us/step - loss: 1.4657 - sparse_categorical_accuracy: 0.2583\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 813us/step - loss: 1.6158 - sparse_categorical_accuracy: 0.2500\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 713us/step - loss: 1.3753 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 873us/step - loss: 1.4446 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 774us/step - loss: 1.4679 - sparse_categorical_accuracy: 0.2667\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 705us/step - loss: 1.5977 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 729us/step - loss: 1.2361 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 708us/step - loss: 1.1320 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 744us/step - loss: 1.4814 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 746us/step - loss: 1.5996 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 684us/step - loss: 1.2590 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 725us/step - loss: 1.6142 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.4460 - sparse_categorical_accuracy: 0.3917 - val_loss: 1.1064 - val_sparse_categorical_accuracy: 0.3000\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 761us/step - loss: 1.1748 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 674us/step - loss: 1.1653 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 702us/step - loss: 1.3913 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 723us/step - loss: 1.1351 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 750us/step - loss: 1.2658 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 745us/step - loss: 1.7286 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 779us/step - loss: 1.3933 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 758us/step - loss: 1.4773 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 790us/step - loss: 1.7606 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 774us/step - loss: 1.4465 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 760us/step - loss: 1.4392 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 719us/step - loss: 1.2645 - sparse_categorical_accuracy: 0.3833\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 884us/step - loss: 1.3930 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 723us/step - loss: 1.2937 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 836us/step - loss: 1.3361 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 802us/step - loss: 1.1168 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 775us/step - loss: 1.4743 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 741us/step - loss: 1.1894 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 803us/step - loss: 1.5088 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.2409 - sparse_categorical_accuracy: 0.3500 - val_loss: 1.1940 - val_sparse_categorical_accuracy: 0.3667\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 831us/step - loss: 1.4089 - sparse_categorical_accuracy: 0.2667\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 862us/step - loss: 1.2310 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 838us/step - loss: 1.0950 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 778us/step - loss: 1.3572 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 820us/step - loss: 1.6642 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 675us/step - loss: 1.4178 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 771us/step - loss: 1.3966 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 817us/step - loss: 1.4530 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 764us/step - loss: 1.4938 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 736us/step - loss: 1.3490 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 740us/step - loss: 1.3646 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 683us/step - loss: 1.1536 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 785us/step - loss: 1.7927 - sparse_categorical_accuracy: 0.2250\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 735us/step - loss: 1.5374 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 677us/step - loss: 1.7052 - sparse_categorical_accuracy: 0.2417\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 661us/step - loss: 1.3402 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 698us/step - loss: 1.4389 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 703us/step - loss: 1.5536 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 806us/step - loss: 1.5410 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.2114 - sparse_categorical_accuracy: 0.3417 - val_loss: 1.4641 - val_sparse_categorical_accuracy: 0.2333\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 888us/step - loss: 1.2396 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 894us/step - loss: 1.7938 - sparse_categorical_accuracy: 0.2667\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 823us/step - loss: 1.1171 - sparse_categorical_accuracy: 0.4500\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 772us/step - loss: 1.3690 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 758us/step - loss: 1.3879 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 808us/step - loss: 1.5363 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 826us/step - loss: 1.2684 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 775us/step - loss: 1.2516 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 766us/step - loss: 1.3411 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 757us/step - loss: 1.3989 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 739us/step - loss: 1.4563 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 740us/step - loss: 1.6649 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 784us/step - loss: 1.3190 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 853us/step - loss: 1.1953 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 858us/step - loss: 1.2280 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 815us/step - loss: 1.4615 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 715us/step - loss: 1.7614 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 763us/step - loss: 1.2555 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 790us/step - loss: 1.4032 - sparse_categorical_accuracy: 0.2417\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.5084 - sparse_categorical_accuracy: 0.3250 - val_loss: 1.6759 - val_sparse_categorical_accuracy: 0.2333\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 865us/step - loss: 1.1803 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 827us/step - loss: 1.3051 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 723us/step - loss: 1.3440 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 782us/step - loss: 1.1701 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 794us/step - loss: 1.3341 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 699us/step - loss: 1.2072 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 738us/step - loss: 1.2931 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 708us/step - loss: 1.2912 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 765us/step - loss: 1.2687 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 765us/step - loss: 1.8613 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 780us/step - loss: 1.1981 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 818us/step - loss: 1.1735 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 810us/step - loss: 1.1985 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 1.3635 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 710us/step - loss: 1.3242 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 743us/step - loss: 1.5691 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 717us/step - loss: 1.6986 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 808us/step - loss: 1.2355 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 744us/step - loss: 1.3748 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4084 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.1475 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 852us/step - loss: 1.1590 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 853us/step - loss: 1.1323 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 886us/step - loss: 1.3940 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 807us/step - loss: 1.4775 - sparse_categorical_accuracy: 0.4083\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 793us/step - loss: 1.2333 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 757us/step - loss: 1.3254 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 759us/step - loss: 1.3565 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 768us/step - loss: 1.2718 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 766us/step - loss: 1.5155 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 738us/step - loss: 1.1746 - sparse_categorical_accuracy: 0.4250\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 776us/step - loss: 1.3676 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 731us/step - loss: 1.5700 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 720us/step - loss: 1.5634 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 709us/step - loss: 1.3620 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 690us/step - loss: 1.4181 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 793us/step - loss: 1.4281 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 727us/step - loss: 1.1850 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 837us/step - loss: 1.2893 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 779us/step - loss: 1.3158 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1814 - sparse_categorical_accuracy: 0.3833 - val_loss: 1.3928 - val_sparse_categorical_accuracy: 0.1667\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 768us/step - loss: 1.4771 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 781us/step - loss: 1.3818 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 1.4699 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 741us/step - loss: 1.3012 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 809us/step - loss: 1.2912 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 784us/step - loss: 1.1206 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 686us/step - loss: 1.4804 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 729us/step - loss: 1.3553 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 743us/step - loss: 1.1500 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 767us/step - loss: 1.1855 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 783us/step - loss: 1.2439 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 832us/step - loss: 1.1940 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 860us/step - loss: 1.1887 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 777us/step - loss: 1.3024 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 716us/step - loss: 1.5387 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 774us/step - loss: 1.3979 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 786us/step - loss: 1.4305 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 771us/step - loss: 1.1411 - sparse_categorical_accuracy: 0.3833\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 768us/step - loss: 1.3054 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.2920 - sparse_categorical_accuracy: 0.3167 - val_loss: 1.3858 - val_sparse_categorical_accuracy: 0.2333\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 768us/step - loss: 1.4749 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 686us/step - loss: 1.3022 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 682us/step - loss: 1.1919 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 704us/step - loss: 1.3997 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 681us/step - loss: 1.1306 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 668us/step - loss: 1.1830 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 680us/step - loss: 1.2653 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 715us/step - loss: 1.1411 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 766us/step - loss: 1.1759 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 690us/step - loss: 1.3015 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 749us/step - loss: 1.1551 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 754us/step - loss: 1.1802 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 717us/step - loss: 1.1792 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 765us/step - loss: 1.4332 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 738us/step - loss: 1.9085 - sparse_categorical_accuracy: 0.2333\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 696us/step - loss: 1.4387 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 713us/step - loss: 1.1936 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 704us/step - loss: 1.4309 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 744us/step - loss: 1.3112 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.6938 - sparse_categorical_accuracy: 0.3000 - val_loss: 1.4989 - val_sparse_categorical_accuracy: 0.2333\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 757us/step - loss: 1.2412 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 664us/step - loss: 1.8503 - sparse_categorical_accuracy: 0.2250\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 702us/step - loss: 1.4078 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 792us/step - loss: 1.1624 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 676us/step - loss: 1.4644 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 685us/step - loss: 1.5177 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 677us/step - loss: 1.3683 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 742us/step - loss: 1.4976 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 671us/step - loss: 1.7130 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 647us/step - loss: 1.5876 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 684us/step - loss: 1.5782 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 698us/step - loss: 1.2147 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 662us/step - loss: 1.2915 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 679us/step - loss: 1.2418 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 758us/step - loss: 1.7084 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 682us/step - loss: 1.3085 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 737us/step - loss: 1.5658 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 719us/step - loss: 1.3348 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 775us/step - loss: 1.4164 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.4264 - sparse_categorical_accuracy: 0.3083 - val_loss: 1.8752 - val_sparse_categorical_accuracy: 0.2333\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 760us/step - loss: 1.4331 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 765us/step - loss: 1.2150 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 823us/step - loss: 1.1640 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 922us/step - loss: 1.6788 - sparse_categorical_accuracy: 0.2500\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2992 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2266 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2969 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3222 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6027 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.8312 - sparse_categorical_accuracy: 0.2583\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.3645 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.8485 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.5360 - sparse_categorical_accuracy: 0.2583\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.3793 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2839 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 932us/step - loss: 1.1726 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2898 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 856us/step - loss: 1.1033 - sparse_categorical_accuracy: 0.4250\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 770us/step - loss: 1.0960 - sparse_categorical_accuracy: 0.4167\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1841 - sparse_categorical_accuracy: 0.3583 - val_loss: 1.1673 - val_sparse_categorical_accuracy: 0.2000\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1443 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2493 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.4536 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.5199 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.5596 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3306 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2402 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.4291 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.6445 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.4805 - sparse_categorical_accuracy: 0.2667\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 978us/step - loss: 1.3515 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.4302 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.3150 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.4418 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 893us/step - loss: 1.2263 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 955us/step - loss: 1.5124 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 806us/step - loss: 1.2319 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 709us/step - loss: 1.4049 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 702us/step - loss: 1.3749 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.2198 - sparse_categorical_accuracy: 0.3917 - val_loss: 1.2145 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 725us/step - loss: 1.3526 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 710us/step - loss: 1.3889 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 812us/step - loss: 1.2304 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 805us/step - loss: 1.3880 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 696us/step - loss: 1.3250 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 728us/step - loss: 1.2716 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 751us/step - loss: 1.2289 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 754us/step - loss: 1.5066 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 805us/step - loss: 1.1557 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 729us/step - loss: 1.3921 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 766us/step - loss: 1.0848 - sparse_categorical_accuracy: 0.4167\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 711us/step - loss: 1.2093 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 769us/step - loss: 1.3799 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 800us/step - loss: 1.4806 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 835us/step - loss: 1.4331 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 909us/step - loss: 1.7638 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 808us/step - loss: 1.1215 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 862us/step - loss: 1.4542 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 1.1495 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1967 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.4666 - val_sparse_categorical_accuracy: 0.2333\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 786us/step - loss: 1.2780 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 691us/step - loss: 1.6007 - sparse_categorical_accuracy: 0.2667\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 696us/step - loss: 1.4579 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 754us/step - loss: 1.3819 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 830us/step - loss: 1.3054 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 759us/step - loss: 1.1150 - sparse_categorical_accuracy: 0.4083\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 744us/step - loss: 1.1962 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 782us/step - loss: 1.4997 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 774us/step - loss: 1.1487 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1450 - sparse_categorical_accuracy: 0.4333\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 682us/step - loss: 1.3661 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 840us/step - loss: 1.3321 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2712 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3192 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2475 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1952 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.3279 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 946us/step - loss: 1.3307 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 827us/step - loss: 1.5249 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.2329 - sparse_categorical_accuracy: 0.4250 - val_loss: 1.2774 - val_sparse_categorical_accuracy: 0.2333\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2960 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.4596 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.7877 - sparse_categorical_accuracy: 0.2583\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.7392 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.4177 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3155 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.4915 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.2970 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.7643 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4153 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.5257 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.5256 - sparse_categorical_accuracy: 0.4250\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1202 - sparse_categorical_accuracy: 0.4083\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.3593 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3758 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.3864 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2496 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2572 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2501 - sparse_categorical_accuracy: 0.3833\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.1668 - sparse_categorical_accuracy: 0.3833 - val_loss: 1.3318 - val_sparse_categorical_accuracy: 0.2333\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 745us/step - loss: 1.2667 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 714us/step - loss: 1.5062 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 761us/step - loss: 1.1365 - sparse_categorical_accuracy: 0.4500\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 734us/step - loss: 1.1487 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 745us/step - loss: 1.1353 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 731us/step - loss: 1.7068 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 710us/step - loss: 1.1294 - sparse_categorical_accuracy: 0.3833\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 723us/step - loss: 1.1922 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 1.2524 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 753us/step - loss: 1.3060 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 757us/step - loss: 1.4321 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 784us/step - loss: 1.3537 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 789us/step - loss: 1.2966 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 778us/step - loss: 2.1449 - sparse_categorical_accuracy: 0.2417\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 823us/step - loss: 1.1340 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 780us/step - loss: 1.5789 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 749us/step - loss: 1.1154 - sparse_categorical_accuracy: 0.4250\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 744us/step - loss: 1.2351 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 709us/step - loss: 1.5796 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.3890 - sparse_categorical_accuracy: 0.3167 - val_loss: 1.1060 - val_sparse_categorical_accuracy: 0.3000\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 786us/step - loss: 1.2324 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 739us/step - loss: 1.1344 - sparse_categorical_accuracy: 0.4250\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 762us/step - loss: 1.3291 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 722us/step - loss: 1.4094 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 687us/step - loss: 1.0792 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 739us/step - loss: 1.1309 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 784us/step - loss: 1.1607 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 698us/step - loss: 1.1088 - sparse_categorical_accuracy: 0.3833\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 741us/step - loss: 1.2377 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 738us/step - loss: 1.5484 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 696us/step - loss: 1.2957 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 869us/step - loss: 1.5603 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2490 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 800us/step - loss: 1.1794 - sparse_categorical_accuracy: 0.4083\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 771us/step - loss: 1.1418 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 736us/step - loss: 1.1802 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 759us/step - loss: 1.3337 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 757us/step - loss: 1.1986 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.5606 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2999 - sparse_categorical_accuracy: 0.3917 - val_loss: 1.3216 - val_sparse_categorical_accuracy: 0.1667\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1712 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3774 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.7123 - sparse_categorical_accuracy: 0.2500\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1829 - sparse_categorical_accuracy: 0.3833\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1403 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1816 - sparse_categorical_accuracy: 0.4167\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.3030 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 976us/step - loss: 1.5046 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 986us/step - loss: 1.2832 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1581 - sparse_categorical_accuracy: 0.4167\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 888us/step - loss: 1.7164 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 765us/step - loss: 1.3803 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 753us/step - loss: 1.2413 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.4711 - sparse_categorical_accuracy: 0.2667\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 880us/step - loss: 1.3885 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 859us/step - loss: 2.0270 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 863us/step - loss: 1.1374 - sparse_categorical_accuracy: 0.3667\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 846us/step - loss: 1.0929 - sparse_categorical_accuracy: 0.3833\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 703us/step - loss: 1.1395 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.5144 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.4851 - val_sparse_categorical_accuracy: 0.3667\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 674us/step - loss: 1.5564 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 719us/step - loss: 1.0880 - sparse_categorical_accuracy: 0.4167\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 723us/step - loss: 1.3327 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 697us/step - loss: 1.3375 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 983us/step - loss: 1.4588 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2747 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.4087 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3552 - sparse_categorical_accuracy: 0.2667\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2330 - sparse_categorical_accuracy: 0.4333\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1281 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 995us/step - loss: 1.4327 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2060 - sparse_categorical_accuracy: 0.3833\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.5279 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1824 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1370 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1387 - sparse_categorical_accuracy: 0.4250\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1757 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.5795 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2146 - sparse_categorical_accuracy: 0.4083\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1143 - sparse_categorical_accuracy: 0.4083 - val_loss: 1.3206 - val_sparse_categorical_accuracy: 0.2333\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 847us/step - loss: 1.3784 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 831us/step - loss: 1.1707 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 817us/step - loss: 1.4920 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1386 - sparse_categorical_accuracy: 0.4333\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1807 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.4638 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1491 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2001 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1851 - sparse_categorical_accuracy: 0.3833\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3104 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2897 - sparse_categorical_accuracy: 0.4083\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.3216 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 913us/step - loss: 1.4298 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 846us/step - loss: 1.5980 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 685us/step - loss: 1.1873 - sparse_categorical_accuracy: 0.3000\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 694us/step - loss: 1.1464 - sparse_categorical_accuracy: 0.4250\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 680us/step - loss: 1.3325 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 710us/step - loss: 1.6123 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 713us/step - loss: 1.3073 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.4631 - sparse_categorical_accuracy: 0.2500 - val_loss: 1.3192 - val_sparse_categorical_accuracy: 0.2333\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 703us/step - loss: 1.2174 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 720us/step - loss: 1.3967 - sparse_categorical_accuracy: 0.2750\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 758us/step - loss: 1.4337 - sparse_categorical_accuracy: 0.4083\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 821us/step - loss: 1.2049 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 790us/step - loss: 1.5001 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 825us/step - loss: 1.3318 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 747us/step - loss: 1.3390 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 772us/step - loss: 1.3824 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 913us/step - loss: 1.2999 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 881us/step - loss: 1.6874 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 934us/step - loss: 1.4630 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.3397 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 836us/step - loss: 1.6617 - sparse_categorical_accuracy: 0.2917\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 738us/step - loss: 1.5361 - sparse_categorical_accuracy: 0.2833\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 761us/step - loss: 1.3030 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 737us/step - loss: 1.0820 - sparse_categorical_accuracy: 0.3917\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 723us/step - loss: 1.3825 - sparse_categorical_accuracy: 0.3333\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 778us/step - loss: 1.2291 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 939us/step - loss: 1.7214 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2764 - sparse_categorical_accuracy: 0.3417 - val_loss: 1.1882 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 722us/step - loss: 1.3084 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 761us/step - loss: 1.6476 - sparse_categorical_accuracy: 0.2167\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 840us/step - loss: 1.2508 - sparse_categorical_accuracy: 0.3833\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 845us/step - loss: 1.3809 - sparse_categorical_accuracy: 0.3083\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 737us/step - loss: 1.2041 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 932us/step - loss: 1.3576 - sparse_categorical_accuracy: 0.3583\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 874us/step - loss: 1.4282 - sparse_categorical_accuracy: 0.2667\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 673us/step - loss: 1.2763 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 1.3048 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 833us/step - loss: 1.4410 - sparse_categorical_accuracy: 0.3500\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 903us/step - loss: 1.1768 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 938us/step - loss: 1.3063 - sparse_categorical_accuracy: 0.3167\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 874us/step - loss: 1.4583 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 894us/step - loss: 1.4132 - sparse_categorical_accuracy: 0.3250\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 802us/step - loss: 1.1806 - sparse_categorical_accuracy: 0.3833\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 775us/step - loss: 1.1921 - sparse_categorical_accuracy: 0.4583\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 678us/step - loss: 1.2681 - sparse_categorical_accuracy: 0.3417\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 847us/step - loss: 1.6239 - sparse_categorical_accuracy: 0.2417\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 753us/step - loss: 1.3923 - sparse_categorical_accuracy: 0.2667\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1247 - sparse_categorical_accuracy: 0.4167 - val_loss: 1.4411 - val_sparse_categorical_accuracy: 0.1667\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 3)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15 (60.00 Byte)\n",
      "Trainable params: 15 (60.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "x_train = datasets.load_iris().data\n",
    "y_train = datasets.load_iris().target\n",
    "\n",
    "np.random.seed(116)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.shuffle(y_train)\n",
    "tf.random.set_seed(116)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(3, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2())\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=500, validation_split=0.2, validation_freq=20)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.9139 - sparse_categorical_accuracy: 0.4333\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 983us/step - loss: 0.9215 - sparse_categorical_accuracy: 0.5833\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 787us/step - loss: 0.9331 - sparse_categorical_accuracy: 0.6833\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 777us/step - loss: 0.7676 - sparse_categorical_accuracy: 0.6750\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 820us/step - loss: 0.9316 - sparse_categorical_accuracy: 0.6417\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 773us/step - loss: 0.7277 - sparse_categorical_accuracy: 0.7417\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.6048 - sparse_categorical_accuracy: 0.7417\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 754us/step - loss: 0.5841 - sparse_categorical_accuracy: 0.8333\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 754us/step - loss: 0.5906 - sparse_categorical_accuracy: 0.7667\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 696us/step - loss: 0.6491 - sparse_categorical_accuracy: 0.6583\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 969us/step - loss: 0.7846 - sparse_categorical_accuracy: 0.6583\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 740us/step - loss: 0.5483 - sparse_categorical_accuracy: 0.7583\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0620 - sparse_categorical_accuracy: 0.5833\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 969us/step - loss: 0.5191 - sparse_categorical_accuracy: 0.7583\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 956us/step - loss: 0.6706 - sparse_categorical_accuracy: 0.7083\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5939 - sparse_categorical_accuracy: 0.7833\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5453 - sparse_categorical_accuracy: 0.7583\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6387 - sparse_categorical_accuracy: 0.7583\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5762 - sparse_categorical_accuracy: 0.7167\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4841 - sparse_categorical_accuracy: 0.8167 - val_loss: 0.7658 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 851us/step - loss: 0.4659 - sparse_categorical_accuracy: 0.8583\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 820us/step - loss: 0.6658 - sparse_categorical_accuracy: 0.7167\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 777us/step - loss: 0.4574 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 724us/step - loss: 0.7573 - sparse_categorical_accuracy: 0.6917\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 861us/step - loss: 0.4963 - sparse_categorical_accuracy: 0.7417\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 817us/step - loss: 0.7578 - sparse_categorical_accuracy: 0.7000\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6505 - sparse_categorical_accuracy: 0.7833\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6676 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5395 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6268 - sparse_categorical_accuracy: 0.7000\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5083 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6927 - sparse_categorical_accuracy: 0.7333\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 893us/step - loss: 0.5532 - sparse_categorical_accuracy: 0.7667\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4173 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4737 - sparse_categorical_accuracy: 0.8083\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4560 - sparse_categorical_accuracy: 0.8500\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 909us/step - loss: 0.4229 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 770us/step - loss: 0.7024 - sparse_categorical_accuracy: 0.6583\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 700us/step - loss: 0.5271 - sparse_categorical_accuracy: 0.7750\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4053 - sparse_categorical_accuracy: 0.9333 - val_loss: 0.5397 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 707us/step - loss: 0.5345 - sparse_categorical_accuracy: 0.7417\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 707us/step - loss: 0.6296 - sparse_categorical_accuracy: 0.6833\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 697us/step - loss: 0.7097 - sparse_categorical_accuracy: 0.7250\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 673us/step - loss: 0.4116 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 702us/step - loss: 0.4007 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 659us/step - loss: 0.3995 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 715us/step - loss: 0.4074 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 667us/step - loss: 0.5672 - sparse_categorical_accuracy: 0.7583\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 716us/step - loss: 0.4188 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 718us/step - loss: 0.3939 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 718us/step - loss: 0.3902 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 667us/step - loss: 0.4151 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 672us/step - loss: 0.4500 - sparse_categorical_accuracy: 0.8417\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 735us/step - loss: 0.7122 - sparse_categorical_accuracy: 0.6417\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 670us/step - loss: 0.4066 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 696us/step - loss: 0.4066 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 730us/step - loss: 0.5259 - sparse_categorical_accuracy: 0.7917\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 738us/step - loss: 0.5063 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 681us/step - loss: 0.4759 - sparse_categorical_accuracy: 0.7917\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5439 - sparse_categorical_accuracy: 0.9000 - val_loss: 0.4375 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 744us/step - loss: 0.4334 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 689us/step - loss: 0.4463 - sparse_categorical_accuracy: 0.8583\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 743us/step - loss: 0.6546 - sparse_categorical_accuracy: 0.7167\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 643us/step - loss: 0.4329 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 699us/step - loss: 0.3938 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 684us/step - loss: 0.3831 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.4088 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 702us/step - loss: 0.5567 - sparse_categorical_accuracy: 0.7167\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 735us/step - loss: 0.4816 - sparse_categorical_accuracy: 0.8333\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 725us/step - loss: 0.3809 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 795us/step - loss: 0.4600 - sparse_categorical_accuracy: 0.8250\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 722us/step - loss: 0.4040 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 934us/step - loss: 0.5205 - sparse_categorical_accuracy: 0.8167\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 782us/step - loss: 0.3898 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 728us/step - loss: 0.3758 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 707us/step - loss: 0.3862 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.4709 - sparse_categorical_accuracy: 0.8083\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 689us/step - loss: 0.7505 - sparse_categorical_accuracy: 0.6500\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 686us/step - loss: 0.4517 - sparse_categorical_accuracy: 0.8167\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4247 - sparse_categorical_accuracy: 0.8917 - val_loss: 0.3579 - val_sparse_categorical_accuracy: 0.9667\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 829us/step - loss: 0.3825 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 719us/step - loss: 0.3750 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 766us/step - loss: 0.3646 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 783us/step - loss: 0.3685 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 790us/step - loss: 0.3762 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 732us/step - loss: 0.3916 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 707us/step - loss: 0.3935 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 712us/step - loss: 0.3819 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 782us/step - loss: 0.5292 - sparse_categorical_accuracy: 0.7833\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 769us/step - loss: 0.3863 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 755us/step - loss: 0.4214 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 711us/step - loss: 0.5057 - sparse_categorical_accuracy: 0.7917\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 687us/step - loss: 0.3802 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 696us/step - loss: 0.3900 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 734us/step - loss: 0.3902 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.5553 - sparse_categorical_accuracy: 0.7667\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 697us/step - loss: 0.4735 - sparse_categorical_accuracy: 0.8500\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.4896 - sparse_categorical_accuracy: 0.8083\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 773us/step - loss: 0.3868 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3767 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.4355 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 685us/step - loss: 0.3686 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 706us/step - loss: 0.3690 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 690us/step - loss: 0.3653 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 738us/step - loss: 0.3816 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 783us/step - loss: 0.4799 - sparse_categorical_accuracy: 0.8167\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 756us/step - loss: 0.4128 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 756us/step - loss: 0.3776 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 802us/step - loss: 0.3858 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 742us/step - loss: 0.3655 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 846us/step - loss: 0.3845 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 818us/step - loss: 0.3602 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 776us/step - loss: 0.3687 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 842us/step - loss: 0.4245 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 735us/step - loss: 0.3649 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 787us/step - loss: 0.3796 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 829us/step - loss: 0.3866 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 802us/step - loss: 0.5151 - sparse_categorical_accuracy: 0.8167\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 793us/step - loss: 0.3670 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 799us/step - loss: 0.3618 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4250 - sparse_categorical_accuracy: 0.8833 - val_loss: 0.3545 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 743us/step - loss: 0.4120 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 706us/step - loss: 0.4212 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 815us/step - loss: 0.3709 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 731us/step - loss: 0.3678 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 845us/step - loss: 0.3754 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 711us/step - loss: 0.3966 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 801us/step - loss: 0.3798 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 806us/step - loss: 0.3802 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 784us/step - loss: 0.3835 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 759us/step - loss: 0.4657 - sparse_categorical_accuracy: 0.8500\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 781us/step - loss: 0.4324 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 744us/step - loss: 0.3547 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 789us/step - loss: 0.3544 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 799us/step - loss: 0.3711 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 697us/step - loss: 0.3760 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 722us/step - loss: 0.3606 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 728us/step - loss: 0.4030 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3554 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 800us/step - loss: 0.4146 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5161 - sparse_categorical_accuracy: 0.7750 - val_loss: 0.3783 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 739us/step - loss: 0.3599 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 757us/step - loss: 0.3627 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 952us/step - loss: 0.3527 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 943us/step - loss: 0.3751 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 681us/step - loss: 0.3809 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 730us/step - loss: 0.3567 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 795us/step - loss: 0.4500 - sparse_categorical_accuracy: 0.8583\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4739 - sparse_categorical_accuracy: 0.8500\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3726 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4448 - sparse_categorical_accuracy: 0.8417\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4299 - sparse_categorical_accuracy: 0.8417\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3738 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4178 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3922 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 918us/step - loss: 0.3862 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 680us/step - loss: 0.3902 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 709us/step - loss: 0.3976 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 746us/step - loss: 0.3633 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 754us/step - loss: 0.4166 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4010 - sparse_categorical_accuracy: 0.9333 - val_loss: 0.4256 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 682us/step - loss: 0.3640 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 685us/step - loss: 0.3880 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 770us/step - loss: 0.3646 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 814us/step - loss: 0.6887 - sparse_categorical_accuracy: 0.7500\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 800us/step - loss: 0.4351 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 745us/step - loss: 0.4423 - sparse_categorical_accuracy: 0.8583\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 781us/step - loss: 0.3929 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 760us/step - loss: 0.3541 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.3611 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 768us/step - loss: 0.3561 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 824us/step - loss: 0.4718 - sparse_categorical_accuracy: 0.8083\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 803us/step - loss: 0.3475 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 823us/step - loss: 0.3544 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 772us/step - loss: 0.3827 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 807us/step - loss: 0.3939 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 810us/step - loss: 0.3894 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 783us/step - loss: 0.4124 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 827us/step - loss: 0.4539 - sparse_categorical_accuracy: 0.8583\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 801us/step - loss: 0.3736 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4065 - sparse_categorical_accuracy: 0.9000 - val_loss: 0.3900 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 871us/step - loss: 0.3617 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 766us/step - loss: 0.4068 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 831us/step - loss: 0.3570 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 781us/step - loss: 0.4188 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 729us/step - loss: 0.3611 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 762us/step - loss: 0.3647 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 851us/step - loss: 0.4120 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 854us/step - loss: 0.3564 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 792us/step - loss: 0.3549 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 743us/step - loss: 0.3995 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 729us/step - loss: 0.3661 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 815us/step - loss: 0.3794 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 718us/step - loss: 0.4507 - sparse_categorical_accuracy: 0.8417\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.3593 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 790us/step - loss: 0.3592 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 983us/step - loss: 0.3797 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3538 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 891us/step - loss: 0.3511 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 803us/step - loss: 0.3557 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3643 - sparse_categorical_accuracy: 0.9333 - val_loss: 0.4179 - val_sparse_categorical_accuracy: 0.9333\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 829us/step - loss: 0.3589 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.4161 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 729us/step - loss: 0.3947 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 700us/step - loss: 0.3477 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 724us/step - loss: 0.3939 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 721us/step - loss: 0.4319 - sparse_categorical_accuracy: 0.8417\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 675us/step - loss: 0.5223 - sparse_categorical_accuracy: 0.7750\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 708us/step - loss: 0.3775 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 703us/step - loss: 0.3813 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 705us/step - loss: 0.3838 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 737us/step - loss: 0.4517 - sparse_categorical_accuracy: 0.8250\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 880us/step - loss: 0.3616 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 781us/step - loss: 0.3534 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 782us/step - loss: 0.3834 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 695us/step - loss: 0.3486 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3792 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 821us/step - loss: 0.3566 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 793us/step - loss: 0.3518 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.3581 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3409 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.3564 - val_sparse_categorical_accuracy: 0.8667\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 857us/step - loss: 0.4187 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4760 - sparse_categorical_accuracy: 0.8500\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3773 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3521 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4826 - sparse_categorical_accuracy: 0.8250\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3783 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3916 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3554 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3545 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 843us/step - loss: 0.3617 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 869us/step - loss: 0.3923 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 806us/step - loss: 0.6143 - sparse_categorical_accuracy: 0.7583\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 883us/step - loss: 0.3584 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 807us/step - loss: 0.3661 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3884 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3899 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3788 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3605 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3635 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3763 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.3370 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3532 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4041 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5787 - sparse_categorical_accuracy: 0.7667\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3483 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4220 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3896 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4291 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3429 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 935us/step - loss: 0.3693 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 852us/step - loss: 0.3588 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 776us/step - loss: 0.3661 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 832us/step - loss: 0.3571 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 772us/step - loss: 0.4366 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 802us/step - loss: 0.4139 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 892us/step - loss: 0.4217 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4357 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3613 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3511 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3871 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3526 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3412 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 703us/step - loss: 0.3785 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 687us/step - loss: 0.3631 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 685us/step - loss: 0.3483 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 658us/step - loss: 0.3442 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 931us/step - loss: 0.3790 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 671us/step - loss: 0.3525 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 709us/step - loss: 0.3489 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 756us/step - loss: 0.3566 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4081 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4124 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 970us/step - loss: 0.3598 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 827us/step - loss: 0.3564 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 710us/step - loss: 0.4005 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 686us/step - loss: 0.3464 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 672us/step - loss: 0.3552 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 694us/step - loss: 0.3616 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 726us/step - loss: 0.4104 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.3722 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 697us/step - loss: 0.3677 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3602 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.3264 - val_sparse_categorical_accuracy: 0.9667\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 777us/step - loss: 0.3526 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 797us/step - loss: 0.3503 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3469 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3952 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4070 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3845 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3820 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3708 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5099 - sparse_categorical_accuracy: 0.8083\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3438 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3426 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3634 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3743 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3477 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4118 - sparse_categorical_accuracy: 0.8583\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3476 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3467 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 954us/step - loss: 0.3445 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 835us/step - loss: 0.3567 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3626 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3253 - val_sparse_categorical_accuracy: 0.9667\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 763us/step - loss: 0.3930 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3619 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3453 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 836us/step - loss: 0.3701 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3626 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3499 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3641 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3414 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3709 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3445 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3747 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3423 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 793us/step - loss: 0.3505 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 676us/step - loss: 0.3763 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.3539 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 760us/step - loss: 0.4016 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 687us/step - loss: 0.3600 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 704us/step - loss: 0.3415 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 811us/step - loss: 0.4072 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5158 - sparse_categorical_accuracy: 0.7917 - val_loss: 0.3256 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 708us/step - loss: 0.3714 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 667us/step - loss: 0.3421 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 677us/step - loss: 0.3508 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 664us/step - loss: 0.3492 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 669us/step - loss: 0.4377 - sparse_categorical_accuracy: 0.8583\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 651us/step - loss: 0.3600 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 673us/step - loss: 0.3566 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 678us/step - loss: 0.4157 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 670us/step - loss: 0.3813 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 659us/step - loss: 0.3948 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 680us/step - loss: 0.3660 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 652us/step - loss: 0.3504 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 643us/step - loss: 0.3536 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 665us/step - loss: 0.3467 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 665us/step - loss: 0.3434 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 683us/step - loss: 0.3427 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 657us/step - loss: 0.3455 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 660us/step - loss: 0.4195 - sparse_categorical_accuracy: 0.8583\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 646us/step - loss: 0.3476 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4096 - sparse_categorical_accuracy: 0.8583 - val_loss: 0.3298 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 679us/step - loss: 0.3869 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 709us/step - loss: 0.3999 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 685us/step - loss: 0.4239 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 710us/step - loss: 0.4248 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3632 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 973us/step - loss: 0.3405 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 864us/step - loss: 0.3421 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3899 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3682 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3406 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3562 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3710 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3412 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3337 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3989 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4201 - sparse_categorical_accuracy: 0.8583\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3728 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3778 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3638 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3412 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.3248 - val_sparse_categorical_accuracy: 0.9667\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 832us/step - loss: 0.4167 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 806us/step - loss: 0.3553 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 785us/step - loss: 0.3721 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 989us/step - loss: 0.4355 - sparse_categorical_accuracy: 0.8417\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3678 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3496 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3413 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3901 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3444 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3377 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3443 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3451 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4205 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3535 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3797 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3517 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3397 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3467 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3610 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3404 - sparse_categorical_accuracy: 0.9667 - val_loss: 0.3332 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 951us/step - loss: 0.3804 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3508 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3971 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3452 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3976 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3417 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3677 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3960 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3857 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4674 - sparse_categorical_accuracy: 0.8333\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4220 - sparse_categorical_accuracy: 0.8583\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 961us/step - loss: 0.3519 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 897us/step - loss: 0.3493 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3450 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3720 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3686 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3665 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3442 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 932us/step - loss: 0.3924 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3792 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.5948 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 797us/step - loss: 0.3657 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 736us/step - loss: 0.3487 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 785us/step - loss: 0.3818 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 962us/step - loss: 0.4457 - sparse_categorical_accuracy: 0.8583\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3872 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3446 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4257 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3380 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3476 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3447 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3913 - sparse_categorical_accuracy: 0.8583\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3835 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3664 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3390 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3452 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3395 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3491 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3725 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3441 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3405 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.3499 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3382 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3507 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 862us/step - loss: 0.4604 - sparse_categorical_accuracy: 0.8250\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 775us/step - loss: 0.3588 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 732us/step - loss: 0.3598 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 929us/step - loss: 0.4834 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4100 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3599 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3749 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4440 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3763 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3355 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3613 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3546 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3838 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3799 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3332 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3580 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4383 - sparse_categorical_accuracy: 0.8500\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3542 - sparse_categorical_accuracy: 0.9333 - val_loss: 0.3885 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 990us/step - loss: 0.3749 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3392 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3482 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3396 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3455 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3605 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3934 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3529 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3392 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3430 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4517 - sparse_categorical_accuracy: 0.8333\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 992us/step - loss: 0.3509 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 914us/step - loss: 0.3772 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 910us/step - loss: 0.3655 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3512 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3770 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3381 - sparse_categorical_accuracy: 0.9833\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3537 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3364 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6361 - sparse_categorical_accuracy: 0.7167 - val_loss: 0.3561 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 771us/step - loss: 0.3419 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 672us/step - loss: 0.3495 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 671us/step - loss: 0.3587 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4626 - sparse_categorical_accuracy: 0.8583\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 824us/step - loss: 0.4853 - sparse_categorical_accuracy: 0.8333\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 900us/step - loss: 0.3965 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 807us/step - loss: 0.3393 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 705us/step - loss: 0.3572 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 838us/step - loss: 0.3549 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3769 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 987us/step - loss: 0.3355 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 753us/step - loss: 0.5356 - sparse_categorical_accuracy: 0.7667\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 755us/step - loss: 0.4675 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 839us/step - loss: 0.5134 - sparse_categorical_accuracy: 0.7833\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 798us/step - loss: 0.3544 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 852us/step - loss: 0.3376 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 833us/step - loss: 0.4078 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4174 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 804us/step - loss: 0.4626 - sparse_categorical_accuracy: 0.8333\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3503 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3183 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 767us/step - loss: 0.3419 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 871us/step - loss: 0.3420 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 848us/step - loss: 0.3442 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 797us/step - loss: 0.3382 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4223 - sparse_categorical_accuracy: 0.8583\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3624 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3627 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3762 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3975 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3440 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3400 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 818us/step - loss: 0.3354 - sparse_categorical_accuracy: 0.9833\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 759us/step - loss: 0.3453 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 856us/step - loss: 0.3439 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 740us/step - loss: 0.3363 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 723us/step - loss: 0.3451 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 704us/step - loss: 0.3440 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 757us/step - loss: 0.3412 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 735us/step - loss: 0.3654 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3894 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.3526 - val_sparse_categorical_accuracy: 0.8667\n",
      "Model: \"iris_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             multiple                  15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15 (60.00 Byte)\n",
      "Trainable params: 15 (60.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "x_train = datasets.load_iris().data\n",
    "y_train = datasets.load_iris().target\n",
    "\n",
    "np.random.seed(116)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(116)\n",
    "np.random.shuffle(y_train)\n",
    "tf.random.set_seed(116)\n",
    "\n",
    "class IrisModel(Model):\n",
    "    def __init__(self):\n",
    "        super(IrisModel, self).__init__()\n",
    "        self.d1 = Dense(3, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2())\n",
    "    \n",
    "    def call(self, x):\n",
    "        y = self.d1(x)\n",
    "        return y\n",
    "\n",
    "model = IrisModel()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=500, validation_split=0.2, validation_freq=20)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 版本: 2.15.1\n",
      "可用的GPU列表： [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow 版本:\", tf.__version__)\n",
    "print(\"可用的GPU列表：\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      " 2285568/11490434 [====>.........................] - ETA: 2:55"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m mnist \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mmnist\n\u001b[0;32m----> 3\u001b[0m (x_train, y_train), (x_test, y_test) \u001b[38;5;241m=\u001b[39m \u001b[43mmnist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/borzoi/lib/python3.10/site-packages/keras/src/datasets/mnist.py:75\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads the MNIST dataset.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03mThis is a dataset of 60,000 28x28 grayscale images of the 10 digits,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m  https://creativecommons.org/licenses/by-sa/3.0/)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     72\u001b[0m origin_folder \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://storage.googleapis.com/tensorflow/tf-keras-datasets/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m )\n\u001b[0;32m---> 75\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmnist.npz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: E501\u001b[39;49;00m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39mload(path, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     83\u001b[0m     x_train, y_train \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_train\u001b[39m\u001b[38;5;124m\"\u001b[39m], f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_train\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/borzoi/lib/python3.10/site-packages/keras/src/utils/data_utils.py:347\u001b[0m, in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m         \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDLProgbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    349\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg\u001b[38;5;241m.\u001b[39mformat(origin, e\u001b[38;5;241m.\u001b[39mcode, e\u001b[38;5;241m.\u001b[39mmsg))\n",
      "File \u001b[0;32m~/anaconda3/envs/borzoi/lib/python3.10/site-packages/keras/src/utils/data_utils.py:87\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m     85\u001b[0m response \u001b[38;5;241m=\u001b[39m urlopen(url, data)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fd:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunk_read(response, reporthook\u001b[38;5;241m=\u001b[39mreporthook):\n\u001b[1;32m     88\u001b[0m         fd\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m~/anaconda3/envs/borzoi/lib/python3.10/site-packages/keras/src/utils/data_utils.py:76\u001b[0m, in \u001b[0;36murlretrieve.<locals>.chunk_read\u001b[0;34m(response, chunk_size, reporthook)\u001b[0m\n\u001b[1;32m     74\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reporthook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/borzoi/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/anaconda3/envs/borzoi/lib/python3.10/socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/borzoi/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/borzoi/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_test, y_test), validation_freq=1)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateds(path, txt):\n",
    "    f = open(txt, 'r')\n",
    "    contents = f.readlines()\n",
    "    f.close()\n",
    "    x, y_ = [], []\n",
    "    for content in contents:\n",
    "        value = content.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gl/projects/Borzoi/paddy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# print current directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './statistics.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data_stats_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./statistics.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_stats_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m data_stats_open:\n\u001b[1;32m      3\u001b[0m         data_stats \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(data_stats_open)\n",
      "File \u001b[0;32m~/anaconda3/envs/borzoi/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './statistics.json'"
     ]
    }
   ],
   "source": [
    "data_stats_file = f\"./statistics.json\"\n",
    "with open(data_stats_file) as data_stats_open:\n",
    "        data_stats = json.load(data_stats_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[3 6 5]\n",
      "  [4 8 9]]\n",
      "\n",
      " [[1 7 9]\n",
      "  [6 8 0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([14, 29, 23])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random int 2 * 2 * 3 matrix\n",
    "# help me write a function to create a random int 2 * 2 * 3 matrix\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "def create_random_matrix():\n",
    "    seed = 1234 \n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    return np.random.randint(0, 10, (2, 2, 3))\n",
    "\n",
    "matrix = create_random_matrix()\n",
    "print(matrix)\n",
    "# use tf.reduce_sum to sum the matrix\n",
    "matrix_sum = tf.reduce_sum(matrix, axis=[0,1])\n",
    "matrix_sum\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "borzoi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
